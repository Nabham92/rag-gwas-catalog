{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ed10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "os.chdir(r\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2acc21a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33336/2430745471.py:10: DtypeWarning: Columns (10,12,13,14,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/significant_associations.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 1000 unique documents (one per study)\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# --- Load abstracts ---\n",
    "with open(\"data/pubmed_abstracts_top1000.json\") as f:\n",
    "    pmid_abstracts = json.load(f)\n",
    "\n",
    "# --- Load and filter data ---\n",
    "df = pd.read_csv(\"data/significant_associations.csv\")\n",
    "df = df.dropna(subset=[\"PUBMEDID\"])\n",
    "df[\"PUBMEDID\"] = df[\"PUBMEDID\"].astype(int).astype(str)\n",
    "df = df[df[\"PUBMEDID\"].isin(pmid_abstracts.keys())]\n",
    "\n",
    "# --- Group by study (PMID) ---\n",
    "grouped = df.groupby(\"PUBMEDID\")\n",
    "docs = []\n",
    "\n",
    "for pmid, group in grouped:\n",
    "    abstract = pmid_abstracts.get(pmid)\n",
    "    if not abstract:\n",
    "        continue\n",
    "\n",
    "    # Unique fields per study\n",
    "    genes = sorted(set(group[\"GENE\"].dropna()))\n",
    "    mapped_genes = sorted(set(group[\"MAPPED_GENE\"].dropna()))\n",
    "    traits = sorted(set(group[\"DISEASE/TRAIT\"].dropna()))\n",
    "    snps = sorted(set(group[\"SNPS\"].dropna()))\n",
    "    chromosomes = sorted(set(map(str, group[\"CHR_ID\"].dropna())))\n",
    "    positions = sorted(set(map(str, group[\"CHR_POS\"].dropna())))\n",
    "    pvals = sorted(set(map(str, group[\"P-VALUE\"].dropna())))\n",
    "    effects = sorted(set(map(str, group[\"OR or BETA\"].dropna())))\n",
    "\n",
    "    ancestries = sorted(set(group[\"INITIAL SAMPLE SIZE\"].dropna()))\n",
    "    authors = sorted(set(group[\"FIRST AUTHOR\"].dropna()))\n",
    "    journals = sorted(set(group[\"JOURNAL\"].dropna()))\n",
    "    dates = sorted(set(group[\"DATE\"].dropna()))\n",
    "\n",
    "    # --- Construct textual content ---\n",
    "    content = (\n",
    "        f\"Study PMID {pmid} reports genetic associations from a GWAS.\\n\\n\"\n",
    "        f\"- SNPs: {', '.join(snps)}\\n\"\n",
    "        f\"- Chromosomes: {', '.join(map(str, chromosomes))}\\n\"\n",
    "        f\"- Positions: {', '.join(map(str, positions))}\\n\"\n",
    "        f\"- Genes (Reported): {', '.join(genes)}\\n\"\n",
    "        f\"- Genes (Mapped): {', '.join(mapped_genes)}\\n\"\n",
    "        f\"- Traits: {', '.join(traits)}\\n\"\n",
    "        f\"- P-values: {', '.join(map(str, pvals))}\\n\"\n",
    "        f\"- Effect sizes (OR/Beta): {', '.join(map(str, effects))}\\n\"\n",
    "        f\"- Ancestries: {', '.join(ancestries)}\\n\"\n",
    "        f\"- Authors: {', '.join(authors)}\\n\"\n",
    "        f\"- Journal(s): {', '.join(journals)}\\n\"\n",
    "        f\"- Publication dates: {', '.join(dates)}\\n\\n\"\n",
    "        f\"Abstract:\\n{abstract}\"\n",
    "    )\n",
    "\n",
    "    # --- Metadata (machine-usable, clean keys) ---\n",
    "    metadata = {\n",
    "        \"pmid\": pmid,\n",
    "        \"snps\": \", \".join(snps),\n",
    "        \"chromosomes\": \", \".join(chromosomes),\n",
    "        \"positions\": \", \".join(positions),\n",
    "        \"genes_reported\": \", \".join(genes),\n",
    "        \"genes_mapped\": \", \".join(mapped_genes),\n",
    "        \"traits\": \", \".join(traits),\n",
    "        \"p_values\": \", \".join(pvals),\n",
    "        \"effect_sizes\": \", \".join(effects),\n",
    "        \"ancestries\": \", \".join(ancestries),\n",
    "        \"authors\": \", \".join(authors),\n",
    "        \n",
    "        \"journals\": \", \".join(journals),\n",
    "        \"publication_dates\": \", \".join(dates),\n",
    "        \"source\": f\"https://pubmed.ncbi.nlm.nih.gov/{pmid}/\"\n",
    "    }\n",
    "\n",
    "\n",
    "    docs.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "print(f\"‚úÖ Created {len(docs)} unique documents (one per study)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830ee764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33336/2046695353.py:21: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Calcul des embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [00:48<00:00, 20.77it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# üìå Param√®tres\n",
    "N_DOCS = 1000\n",
    "INDEX_DIR = \"rag_gwas_index\"\n",
    "\n",
    "# üìö Sous-√©chantillon\n",
    "subset_docs = docs[:N_DOCS]\n",
    "\n",
    "# üî§ Texte et m√©tadonn√©es\n",
    "texts = [doc.page_content for doc in subset_docs]\n",
    "metas = [doc.metadata for doc in subset_docs]\n",
    "\n",
    "# üß† Cr√©er l'embedding Ollama\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# üî¢ Embeddings avec barre de progression\n",
    "print(\"‚è≥ Calcul des embeddings...\")\n",
    "embeddings = [embedding.embed_query(text) for text in tqdm(texts)]\n",
    "\n",
    "# üìÑ Cr√©er les documents avec embeddings\n",
    "docs_embedded = [\n",
    "    Document(page_content=texts[i], metadata=metas[i])\n",
    "    for i in range(len(texts))\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4fa18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Indexation de 1000 documents...\n",
      "‚úÖ Index sauvegard√© dans 'rag_gwas_index' avec 1000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33336/2615584903.py:19: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "# üîß Dossier o√π l‚Äôindex sera sauvegard√©\n",
    "INDEX_DIR = \"rag_gwas_index\"\n",
    "\n",
    "# üßπ Supprimer l'ancien index si pr√©sent\n",
    "shutil.rmtree(INDEX_DIR, ignore_errors=True)\n",
    "\n",
    "# üß† Cr√©er le vectorstore avec les bons documents\n",
    "print(f\"üì¶ Indexation de {len(docs_embedded)} documents...\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs_embedded,\n",
    "    embedding=embedding,\n",
    "    persist_directory=INDEX_DIR\n",
    ")\n",
    "\n",
    "# üíæ Sauvegarde sur disque\n",
    "vectorstore.persist()\n",
    "print(f\"‚úÖ Index sauvegard√© dans '{INDEX_DIR}' avec {len(docs_embedded)} documents.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c086e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33336/4001839455.py:15: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n",
      "/tmp/ipykernel_33336/4001839455.py:26: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"mistral:instruct\")\n",
      "/tmp/ipykernel_33336/4001839455.py:71: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loading vectorstore for QA...\n",
      "\n",
      "üîé Retrieved Documents:\n",
      "‚Üí PMID: 19430479\n",
      "‚Üí PMID: 28498854\n",
      "‚Üí PMID: 28739976\n",
      "‚Üí PMID: 25249183\n",
      "‚Üí PMID: 26390057\n",
      "\n",
      "üß† Generated Answer:\n",
      "\n",
      " The study you've provided is a genome-wide association and replication study of blood pressure phenotypes among individuals of East Asian, European, and South Asian ancestry. The research was conducted by up to 320,251 individuals from various contributing institutions. They identified 12 new genetic loci associated with blood pressure (P value ranges from 3.9e-11 to 5.0e-21).\n",
      "\n",
      "The sentinel SNPs at the newly discovered loci suggest that DNA methylation may play a role in blood pressure regulation, as they are enriched for association with multiple nearby CpG sites. The genes involved in vascular smooth muscle (IGFBP3, KCNK3, PDE3A, and PRDM6) and renal function (ARHGAP24, OSR1, SLC22A7, and TBX2) are implicated in these new genetic variants.\n",
      "\n",
      "These newly identified genetic variations are found to predict increased left ventricular mass, circulating levels of NT-proBNP, and cardiovascular and all-cause mortality (P value ranges from 0.04 to 8.6e-6). This study provides new evidence for the role of DNA methylation in blood pressure regulation.\n",
      "\n",
      "The DOI and PMID for this study are:\n",
      "DOI: 10.1038/ng.3405\n",
      "PMID: 26390057\n",
      "\n",
      "üìö Sources:\n",
      "- https://pubmed.ncbi.nlm.nih.gov/19430479/\n",
      "- https://pubmed.ncbi.nlm.nih.gov/28498854/\n",
      "- https://pubmed.ncbi.nlm.nih.gov/28739976/\n",
      "- https://pubmed.ncbi.nlm.nih.gov/25249183/\n",
      "- https://pubmed.ncbi.nlm.nih.gov/26390057/\n",
      "\n",
      "üß† Verdict:\n",
      " YES\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# --- Parameters ---\n",
    "INDEX_DIR = \"rag_gwas_index\"\n",
    "\n",
    "# --- RAG QA PIPELINE ---\n",
    "\n",
    "# üîÅ Reload vectorstore\n",
    "print(\"üîÅ Loading vectorstore for QA...\")\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=INDEX_DIR,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "# üîç Retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 5}\n",
    ")\n",
    "\n",
    "# ü§ñ Local LLM\n",
    "llm = Ollama(model=\"mistral:instruct\")\n",
    "\n",
    "# üìú Structured Prompt\n",
    "system_prompt = \"\"\"\n",
    "You are a human genetics expert. Answer the user's question **using only the provided documents**.\n",
    "\n",
    "Your answer must have two parts:\n",
    "\n",
    "1. üí° **Gene summary**:\n",
    "   - Start with a concise list or sentence stating which genes are associated with the disease mentioned in the question ALWAYS citing the source.\n",
    "\n",
    "2. üìö **Study-by-study details**:\n",
    "   - For each of the 5 documents:\n",
    "     - Mention the **PMID**\n",
    "     - Summarize the **associated genes**, **population studied**, **identified loci**, and any other relevant info.\n",
    "     - If the document does not mention any genes, say: ‚ÄúThis study does not mention any gene associated with the condition.‚Äù\n",
    "\n",
    "‚ùå Do NOT infer or guess.\n",
    "‚ùå Do NOT fabricate any information.\n",
    "‚úÖ Use only the content of the documents below.\n",
    "\n",
    "\n",
    "\n",
    "Question: {question}\n",
    "=========\n",
    "{context}\n",
    "=========\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=system_prompt\n",
    ")\n",
    "\n",
    "# üîó QA Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "\n",
    "# üß† Ask your question\n",
    "query = \"Which genes are associated with hypertension?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"\\nüîé Retrieved Documents:\")\n",
    "pmid_set = set()\n",
    "for doc in result[\"source_documents\"]:\n",
    "    pmid = doc.metadata.get(\"pmid\", \"unknown\")\n",
    "    if pmid not in pmid_set:\n",
    "        print(\"‚Üí PMID:\", pmid)\n",
    "        pmid_set.add(pmid)\n",
    "\n",
    "print(\"\\nüß† Generated Answer:\\n\")\n",
    "print(result[\"result\"])\n",
    "\n",
    "print(\"\\nüìö Sources:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(\"-\", doc.metadata.get(\"source\", \"no source\"))\n",
    "\n",
    "# --- Automated Judgment ---\n",
    "critic_prompt = f\"\"\"\n",
    "You are an expert scientific reviewer.\n",
    "\n",
    "Evaluate the following RESPONSE and compare it to the DOCUMENTS.\n",
    "\n",
    "‚ö†Ô∏è Only answer \"YES\" if the response is **explicitly supported** by facts present in the documents.\n",
    "\n",
    "Rules:\n",
    "- If you are not completely sure, say \"NO\".\n",
    "- First line MUST be \"YES\" or \"NO\" (in ALL CAPS, nothing else).\n",
    "- If \"NO\", give a short explanation on the second line.\n",
    "\n",
    "--- RESPONSE TO EVALUATE ---\n",
    "{result['result']}\n",
    "\n",
    "--- DOCUMENTS USED ---\n",
    "{[doc.page_content[:1000] for doc in result['source_documents']]}\n",
    "\n",
    "Was the response 100% faithful to the information provided in the documents?\n",
    "\"\"\"\n",
    "\n",
    "judgment = llm.invoke(critic_prompt)\n",
    "print(\"\\nüß† Verdict:\\n\", judgment.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af1285fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Synthesized Answer:\n",
      "\n",
      " Summary:\n",
      "The studies collectively suggest several genes associated with hypertension. These include ATP2B1 (PMID 19430479, 25249183), CACNB2, TBX3-AS1, SH2B3, ULK4 (PMID 19430479), GPR20, TARID, and FRMD3 (PMID 28498854), HSPB7, TNXB (PMID 28739976, 25249183), CACNA1D (PMID 25249183), CASZ1, FGF5, HECTD4, LINC01752 - LINC02871, PRDM8, RN7SL865P - LINC02463, SOX6 (PMID 25249183), and AKT2, EBF2, NFKBIA, IGFBP3, KCNK3, PDE3A, PRDM6, ARHGAP24, OSR1, SLC22A7, TBX2 (PMID 26390057).\n",
      "\n",
      "Grouped by Biological Relevance:\n",
      "\n",
      "1. **Vascular Function**: TNXB (associated in multiple studies), IGFBP3, KCNK3, PDE3A, ARHGAP24, and OSR1 (PMID 26390057). These genes play roles in vascular smooth muscle function.\n",
      "\n",
      "2. **Renal Function**: TNXB (associated in multiple studies), SLC22A7, and TBX2 (PMID 26390057) are associated with renal function. Additionally, EBF2 and NFKBIA were found to be involved in blood pressure regulation in a study (PMID 28739976), but their direct relevance to renal function is not explicitly stated.\n",
      "\n",
      "3. **Signal Transduction**: ATP2B1, CACNB2, SH2B3, ULK4 (PMID 19430479), GPR20 (PMID 28498854, 25249183), and PRDM8 (PMID 25249183) are involved in signal transduction pathways.\n",
      "\n",
      "4. **Others**: AKT2, CACNA1D, CASZ1, FGF5, HECTD4, LINC01752 - LINC02871, RN7SL865P - LINC02463, SOX6, and UBA52P4 (PMID 25249183) are also associated with hypertension, but their specific biological relevance is not explicitly stated in the provided information.\n",
      "\n",
      "It's important to note that while these genes have been associated with hypertension in various studies, further validation and research are required before definitive conclusions can be drawn. Also, the results may not be generalizable to all populations or ethnicities, as some studies focus on specific ancestry populations. Always consult with a healthcare professional for specific medical advice.\n",
      "\n",
      "üìö Sources:\n",
      "- https://pubmed.ncbi.nlm.nih.gov/19430479/\n",
      "- https://pubmed.ncbi.nlm.nih.gov/28498854/\n",
      "- https://pubmed.ncbi.nlm.nih.gov/28739976/\n",
      "- https://pubmed.ncbi.nlm.nih.gov/25249183/\n",
      "- https://pubmed.ncbi.nlm.nih.gov/26390057/\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "# --- Parameters ---\n",
    "INDEX_DIR = \"rag_gwas_index\"\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma(persist_directory=INDEX_DIR, embedding_function=embedding)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "llm = Ollama(model=\"mistral:instruct\")\n",
    "\n",
    "# --- Step 1: Get 5 documents\n",
    "docs = retriever.get_relevant_documents(\"Which genes are associated with hypertension?\")\n",
    "\n",
    "# --- Step 2: Ask the question on each document individually\n",
    "single_doc_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a human genetics expert.\n",
    "\n",
    "Using ONLY the content below, answer the question.\n",
    "\n",
    "Content:\n",
    "---------\n",
    "{context}\n",
    "---------\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    ")\n",
    "\n",
    "answers = []\n",
    "for i, doc in enumerate(docs):\n",
    "    context = doc.page_content\n",
    "    question = \"Which genes are associated with hypertension?\"\n",
    "    prompt = single_doc_prompt.format(context=context, question=question)\n",
    "    response = llm.invoke(prompt)\n",
    "    answers.append((doc.metadata.get(\"pmid\", f\"doc_{i+1}\"), response.strip()))\n",
    "\n",
    "# --- Step 3: Summarize the 5 answers together\n",
    "all_responses = \"\\n\\n\".join(\n",
    "    f\"PMID {pmid}:\\n{answer}\" for pmid, answer in answers\n",
    ")\n",
    "\n",
    "synthesis_prompt = f\"\"\"\n",
    "You are a scientific summarizer.\n",
    "\n",
    "You are given 5 independent answers to the question \"Which genes are associated with hypertension?\", each based on a scientific document.\n",
    "\n",
    "Your task is to write a detailed, structured synthesis that:\n",
    "\n",
    "1. **Starts with a clear summary** of the main genetic findings across all studies.\n",
    "2. **Groups genes by biological relevance** (e.g., vascular function, renal function, signal transduction, etc.) if such information is available.\n",
    "3. **Mentions the study (PMID)** that supports each gene's association.\n",
    "4. Provides short contextual details for each gene (e.g., role, type of variant, pathway) **only if present in the text**.\n",
    "5. Does **NOT invent or infer** anything not in the original answers.\n",
    "\n",
    "Here is the content to synthesize:\n",
    "---\n",
    "{all_responses}\n",
    "---\n",
    "Now write the final answer.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "final_answer = llm.invoke(synthesis_prompt)\n",
    "\n",
    "# --- Display\n",
    "print(\"\\nüß† Synthesized Answer:\\n\")\n",
    "print(final_answer)\n",
    "\n",
    "print(\"\\nüìö Sources:\")\n",
    "for doc in docs:\n",
    "    print(\"-\", doc.metadata.get(\"source\", \"no source\"))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
